% From the Research Methods workbook, page 242.
%
% This section contains the review of the relevant
% literature. For technical papers the literature review focuses on
% highly relevant papers. In psychology, depending on the journal,
% the literature review may provide a wider overview of related
% topics.

\subsection{Related Work}
Guardrails for LLMs in the medical domain have been explored in various studies.
The article by \citep{kang2024r} discusses a complex guardrail that combine learning and reasoning to ensure safe and correct outputs from LLMs.
The probability of unsafety is estimated for multiple categories based on a trained model for reasoning about safety.
In the reasoning phase the probability of unsafety is used to determine whether the output is safe or not using a weighted sum.
The reasoning approach provides an interesting perspective on how to ensure safety in LLM outputs, but it does not guarantee correctness in the medical domain.
Reasoning about safety categories did provide a significantly more effective guardrail compared to more simplistic models.
In \citep{hsu2025medplan} a more systematic approach of reasoning about medical plans is presented.
The guardrail takes the approach of SOAP (Subjective, Objective, Assessment, Plan) to generate medical plans.
This approach is more focused on the planning aspect of medical care, rather than directly addressing correctness in medication-related queries.
It is interesting to see that the approach reflects the medical practice of SOAP, which is a common method used by healthcare professionals to document patient care.
Better performance on safe responses from LLMs can be achieved by providing well structured data to the LLM as shown in \citep{wu2024medical}.
The authors created a graph structure of medical sources that links subjects to medical books \& papers.
The medical books \& papers are then linked to formal medical vocabularies.
This approach of applying RAG with a graph structure allows for more accurate and reliable responses from LLMs.
The experiments showed a significant improvement to the safety of LLM outputs when using this structured approach.
s